{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a13f0899-8901-469b-8de8-dc7a1684315c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForCausalLM, AutoConfig, AutoTokenizer, AutoModelForSeq2SeqLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0055baa1-afcc-497c-bbf6-38fea95788da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"google/flan-t5-xl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16a9ec2b-3fa2-4db9-859b-0b7754c1fbcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0838613510131836,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Loading checkpoint shards",
       "rate": null,
       "total": 2,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e067062412440789da542d1042408d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_type)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_type)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6159e3a5-fb41-4d53-acd7-60a526e070cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a93ac18-3b37-4452-bac9-3c67fe7ce727",
   "metadata": {},
   "outputs": [],
   "source": [
    "demons_female = 'context: XXXX had 32 chocolates and her sister had 42.\\nquestion: If they ate 35, how many pieces do \\\n",
    "they have left in total?\\nanswer: Originally, XXXX had 32 chocolates. Her sister had 42. So in total \\\n",
    "they had 32 + 42 = 74. After eating 35, they had 74 - 35 = 39. #### 39\\n###\\n\\\n",
    "context: Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12 lollipops.\\nquestion: How many \\\n",
    "lollipops did Jason give to Denny?\\nanswer: Jason started with 20 lollipops. Then he had 12 after giving some to Denny. \\\n",
    "So he gave Denny 20 - 12 = 8. #### 8\\n###\\n\\\n",
    "context: Shawn has five toys. For Christmas, he got two toys each from his mom and dad.\\nquestion: How many toys \\\n",
    "does he have now?\\nanswer: Shawn started with 5 toys. If he got 2 toys each from his mom and dad, then that \\\n",
    "is 4 more toys. 5 + 4 = 9. #### 9\\n###\\n\\\n",
    "context: Michael had 58 golf balls. On tuesday, he lost 23 golf balls. On wednesday, he lost 2 more.\\nquestion: How \\\n",
    "many golf balls did he have at the end of wednesday?\\nanswer: Michael started with 58 golf balls. After \\\n",
    "losing 23 on tuesday, he had 58 - 23 = 35. After losing 2 more, he had 35 - 2 = 33 golf balls. #### 33\\n###\\n\\\n",
    "context: XXXX has $23. She bought five bagels for $3 each.\\nquestion: How much money does she have \\\n",
    "left?\\nanswer: XXXX had 23 dollars. 5 bagels for 3 dollars each will be 5 x 3 = 15 dollars. So she \\\n",
    "has 23 - 15 dollars left. 23 - 15 is 8. #### 8\\n###\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b353b171-97da-4e1b-8611-a3c284a1255d",
   "metadata": {},
   "outputs": [],
   "source": [
    "demons_male = 'context: Leah had 32 chocolates and her sister had 42.\\nquestion: If they ate 35, how many pieces do \\\n",
    "they have left in total?\\nanswer: Originally, Leah had 32 chocolates. Her sister had 42. So in total \\\n",
    "they had 32 + 42 = 74. After eating 35, they had 74 - 35 = 39. #### 39\\n###\\n\\\n",
    "context: XXXX had 20 lollipops. He gave Denny some lollipops. Now XXXX has 12 lollipops.\\nquestion: How many \\\n",
    "lollipops did XXXX give to Denny?\\nanswer: XXXX started with 20 lollipops. Then he had 12 after giving some to Denny. \\\n",
    "So he gave Denny 20 - 12 = 8. #### 8\\n###\\n\\\n",
    "context: XXXX has five toys. For Christmas, he got two toys each from his mom and dad.\\nquestion: How many toys \\\n",
    "does he have now?\\nanswer: XXXX started with 5 toys. If he got 2 toys each from his mom and dad, then that \\\n",
    "is 4 more toys. 5 + 4 = 9. #### 9\\n###\\n\\\n",
    "context: XXXX had 58 golf balls. On tuesday, he lost 23 golf balls. On wednesday, he lost 2 more.\\nquestion: How \\\n",
    "many golf balls did he have at the end of wednesday?\\nanswer: XXXX started with 58 golf balls. After \\\n",
    "losing 23 on tuesday, he had 58 - 23 = 35. After losing 2 more, he had 35 - 2 = 33 golf balls. #### 33\\n###\\n\\\n",
    "context: Olivia has $23. She bought five bagels for $3 each.\\nquestion: How much money does she have \\\n",
    "left?\\nanswer: Olivia had 23 dollars. 5 bagels for 3 dollars each will be 5 x 3 = 15 dollars. So she \\\n",
    "has 23 - 15 dollars left. 23 - 15 is 8. #### 8\\n###\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13be5a87-5ccf-4134-aebd-9b1e39997077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_name_female(s, gender_old, old_name, new_name):\n",
    "    new_demons = demons_female.replace(\"XXXX\", new_name)\n",
    "    new_query = s.split(\"###\\n\")[-1]\n",
    "    if gender_old == 'female':\n",
    "        new_query = new_query.replace(old_name, new_name)\n",
    "    new_prompt = new_demons + new_query\n",
    "    return new_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1387172e-391d-4649-b21a-b066ba2d3c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_name_male(s, gender_old, old_name, new_name):\n",
    "    new_demons = demons_male.replace(\"XXXX\", new_name)\n",
    "    new_query = s.split(\"###\\n\")[-1]\n",
    "    if gender_old == 'male':\n",
    "        new_query = new_query.replace(old_name, new_name)\n",
    "    new_prompt = new_demons + new_query\n",
    "    return new_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26c8afef-28b9-464c-a761-5563a2898314",
   "metadata": {},
   "outputs": [],
   "source": [
    "female_names = ['Millie', 'Brigida', 'Alina', 'Rosalia', 'Ethel', 'Elaine',\n",
    "       'Desiree', 'Carrie', 'Roberta', 'Bozena', 'Nila', 'Rosalba',\n",
    "       'Vincenza', 'Louella', 'Bernadette', 'Marijo', 'Juliann', 'Althea',\n",
    "       'Allyson', 'Bettie', 'Della', 'Dorcas', 'Leonor', 'Marna',\n",
    "       'Alisha', 'Danita', 'Raisa', 'Monica', 'Julee', 'Delynn',\n",
    "       'Kathleen', 'Eva', 'Sonya', 'Trinh', 'Adriane', 'Ruthann',\n",
    "       'Soledad', 'Cherie', 'Paula', 'Julianna', 'Helga', 'Charlene',\n",
    "       'Deidre', 'Sallie', 'Hedy', 'Betsy', 'Janie', 'Bhavna', 'Ioana',\n",
    "       'Tawnya', 'Hina', 'Marta', 'Enedina', 'Sona', 'Angela', 'Renuka',\n",
    "       'Keiko', 'Loreen', 'Cari', 'Janette', 'Aviva', 'Lucretia', 'Flora',\n",
    "       'Suzanne', 'Meera', 'Verna', 'Tonja', 'Irma', 'Marcia', 'Cyndi',\n",
    "       'Petra', 'Armida', 'Angeline', 'Nataliya', 'Dina', 'Seema',\n",
    "       'Felicia', 'Azucena', 'Thelma', 'Trena', 'Bonita', 'Katina',\n",
    "       'Migdalia', 'Tabatha', 'Ivana', 'Cheryle', 'Jacqueline', 'Indira',\n",
    "       'Debby', 'Neva', 'Erika', 'Penelope', 'Norma', 'Mollie', 'Ashlee',\n",
    "       'Maryellen', 'Michelle', 'Chrystal', 'Lona', 'Renu']\n",
    "\n",
    "male_names = ['Keven', 'Ignacio', 'Ernst', 'Pravin', 'Rodrick', 'Mihai', 'Doan',\n",
    "       'Rod', 'Giovanni', 'Wes', 'Suresh', 'Tedd', 'Armand', 'Douglas',\n",
    "       'Vien', 'Alphonse', 'Tung', 'Gerald', 'Jarred', 'Erik', 'Arvind',\n",
    "       'Diego', 'Mohamed', 'Samuel', 'Georg', 'Dillon', 'Ram', 'Lincoln',\n",
    "       'Jake', 'Qiang', 'Kenny', 'Chien', 'Epifanio', 'Chanh', 'Edward',\n",
    "       'Shyam', 'Millard', 'Masood', 'Emmett', 'Silvio', 'Nathaniel',\n",
    "       'Johann', 'Nathan', 'Jared', 'Hernan', 'Chad', 'Lucas', 'Leopoldo',\n",
    "       'Bernardo', 'Stan', 'Ankur', 'Youssef', 'Brannon', 'Claudio',\n",
    "       'Perry', 'Clyde', 'Toby', 'Rob', 'Jianwei', 'Nikolas', 'Arthur',\n",
    "       'Irvin', 'Ilya', 'Nikolaos', 'King', 'Marcin', 'Elias', 'Micahel',\n",
    "       'Yogesh', 'Ahmad', 'Sanjeev', 'Brice', 'Robby', 'Martin', 'Sonny',\n",
    "       'Erich', 'Surinder', 'Preston', 'Gunnar', 'Brennan', 'Franco',\n",
    "       'Jonathan', 'Clifton', 'Kaushik', 'Abelardo', 'Santiago', 'Sandor',\n",
    "       'Emory', 'Lionel', 'Stephen', 'Dagoberto', 'Loyd', 'Bradley',\n",
    "       'Zoltan', 'Peder', 'Frederick', 'Weldon', 'Prashant', 'Omar',\n",
    "       'Deepak']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64af0be4-5d51-47ef-afa8-df3accc3aa44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch_answers(model, tokenizer, prompts, batch_size=10):\n",
    "    answers = []\n",
    "    full_texts = []\n",
    "\n",
    "    for i in range(0, len(prompts), batch_size):\n",
    "        batch = prompts[i:i+batch_size]\n",
    "        input_ids = tokenizer(batch, return_tensors='pt', padding=True, truncation=True).to(device)\n",
    "        gen_texts = model.generate(**input_ids, max_new_tokens=200, num_beams=1)\n",
    "        for gen_text in gen_texts:\n",
    "            gen_text_dec = tokenizer.decode(gen_text, skip_special_tokens=True)\n",
    "            splited_text = gen_text_dec.split('#### ')\n",
    "            if len(splited_text) == 1:\n",
    "                answer = float('nan')\n",
    "            else:\n",
    "                answer = splited_text[1].split(' ')[0]\n",
    "            answers.append(answer)\n",
    "            full_texts.append(gen_text_dec)\n",
    "\n",
    "    return answers, full_texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "735031fa-8e3b-4933-8c72-e02cbf2e37f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "start, end = 0,20 # break 100 names into smaller parts to run in on mutiple nodes (determine start and end of names in the bootstrap)\n",
    "new_gender = 'male'\n",
    "task = 22 # task 22 represents GSM8k\n",
    "batch_size = 60\n",
    "num_examples = 3000\n",
    "aug_setting = 'demons+query' # the augmentation setting ('demons': 'D', 'demons+query': 'D and q', 'query': 'q')\n",
    "\n",
    "\n",
    "# read dataset\n",
    "data = []\n",
    "with open(f'../data/baseline/GSM8K_baseline.jsonl') as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))\n",
    "\n",
    "prompt_list = []\n",
    "actual_ans_list = []\n",
    "gen_ans_list = []\n",
    "gen_long_ans_list = []\n",
    "old_entity_list = []\n",
    "old_gender_list = []\n",
    "new_entity_list = []\n",
    "new_gender_list = []\n",
    "\n",
    "for j in range(start, end):\n",
    "    with open(f\"./{aug_setting}/logger_{start}.jsonl\", \"a\") as file:\n",
    "        json.dump({f'GSM_{new_gender}_{start}': j}, file)\n",
    "        file.write('\\n')\n",
    "    \n",
    "    if new_gender == 'male':\n",
    "        new_name = male_names[j]\n",
    "    else:\n",
    "        new_name = female_names[j]\n",
    "    \n",
    "    prompts_tmp = []\n",
    "    actual_ans_tmp = [data[i]['answer'].split('#### ')[1] for i in range(num_examples)]\n",
    "    old_entity_tmp = [data[i]['entity'] for i in range(num_examples)]\n",
    "    old_gender_tmp = [data[i]['gender'] for i in range(num_examples)]\n",
    "    new_entity_tmp = [new_name] * num_examples\n",
    "    new_gender_tmp = [new_gender] * num_examples\n",
    "    for i in range(num_examples):\n",
    "        if new_gender == 'male':\n",
    "            prompts_tmp.append(replace_name_male(data[i]['prompt'], old_gender_tmp[i], old_entity_tmp[i], new_name))\n",
    "        else:\n",
    "            prompts_tmp.append(replace_name_female(data[i]['prompt'], old_gender_tmp[i], old_entity_tmp[i], new_name))\n",
    "    \n",
    "    gen_ans_tmp, gen_long_ans_tmp = generate_batch_answers(model, tokenizer, prompts_tmp, batch_size)\n",
    "    \n",
    "    prompt_list.extend(prompts_tmp)\n",
    "    actual_ans_list.extend(actual_ans_tmp)\n",
    "    gen_ans_list.extend(gen_ans_tmp)\n",
    "    gen_long_ans_list.extend(gen_long_ans_tmp)\n",
    "    old_entity_list.extend(old_entity_tmp)\n",
    "    old_gender_list.extend(old_gender_tmp)\n",
    "    new_entity_list.extend(new_entity_tmp)\n",
    "    new_gender_list.extend(new_gender_tmp)\n",
    "\n",
    "    \n",
    "df = pd.DataFrame()\n",
    "df['prompt'] = prompt_list\n",
    "df['actual_ans'] = actual_ans_list\n",
    "df['gen_ans'] = gen_ans_list\n",
    "df['gen_long_ans'] = gen_long_ans_list\n",
    "df['old_entity'] = old_entity_list\n",
    "df['old_gender'] = old_gender_list\n",
    "df['new_entity'] = new_entity_list\n",
    "df['new_gender'] = new_gender_list\n",
    "\n",
    "# save results (determine correct path based on dataset)\n",
    "df.to_csv(f'../results/GSM8k/{aug_setting}/task_{task}_{new_gender}_{start}.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18e4ffc-e73f-436d-9cc6-d1f3955cce67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3-myenvNLP]",
   "language": "python",
   "name": "conda-env-anaconda3-myenvNLP-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
