{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a13f0899-8901-469b-8de8-dc7a1684315c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForCausalLM, AutoConfig, AutoTokenizer, AutoModelForSeq2SeqLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0055baa1-afcc-497c-bbf6-38fea95788da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"google/flan-t5-xl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16a9ec2b-3fa2-4db9-859b-0b7754c1fbcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.06949162483215332,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Loading checkpoint shards",
       "rate": null,
       "total": 2,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "883da9db47114b69b050fe5c0daa7d1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_type)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_type)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6159e3a5-fb41-4d53-acd7-60a526e070cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read list of selected based on validation performance\n",
    "saved_entity = []\n",
    "with open('../results/GSM8k/saved_entity/task_22.json') as f:\n",
    "    saved_entity = json.load(f)\n",
    "    saved_entity = saved_entity['demons+query']\n",
    "    saved_entity = list(saved_entity.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "471a7e03-5892-473a-8b58-c1349dbd3eae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Douglas',\n",
       " 'Juliann',\n",
       " 'Kathleen',\n",
       " 'Ernst',\n",
       " 'Tonja',\n",
       " 'Angela',\n",
       " 'Hina',\n",
       " 'Diego',\n",
       " 'Bradley',\n",
       " 'Jonathan',\n",
       " 'Leopoldo',\n",
       " 'Youssef',\n",
       " 'Epifanio',\n",
       " 'Sanjeev',\n",
       " 'Zoltan',\n",
       " 'Jianwei',\n",
       " 'Abelardo',\n",
       " 'Alphonse',\n",
       " 'Dagoberto',\n",
       " 'Nathaniel']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73f1785e-d126-4f51-aacc-27c65e86424b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(model, tokenizer, prompt):\n",
    "    input_ids = tokenizer(prompt, return_tensors='pt').to(device)\n",
    "    gen_text = model.generate(**input_ids, max_new_tokens=200, num_beams=1)\n",
    "    gen_text_dec = tokenizer.decode(gen_text[0], skip_special_tokens=True)\n",
    "    splited_text = gen_text_dec.split('#### ')\n",
    "    if len (splited_text) == 1:\n",
    "        answer = float('nan')\n",
    "    else:\n",
    "        answer = splited_text[1].split(' ')[0]\n",
    "    return (answer, gen_text_dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a93ac18-3b37-4452-bac9-3c67fe7ce727",
   "metadata": {},
   "outputs": [],
   "source": [
    "demons_female = 'context: XXXX had 32 chocolates and her sister had 42.\\nquestion: If they ate 35, how many pieces do \\\n",
    "they have left in total?\\nanswer: Originally, XXXX had 32 chocolates. Her sister had 42. So in total \\\n",
    "they had 32 + 42 = 74. After eating 35, they had 74 - 35 = 39. #### 39\\n###\\n\\\n",
    "context: Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12 lollipops.\\nquestion: How many \\\n",
    "lollipops did Jason give to Denny?\\nanswer: Jason started with 20 lollipops. Then he had 12 after giving some to Denny. \\\n",
    "So he gave Denny 20 - 12 = 8. #### 8\\n###\\n\\\n",
    "context: Shawn has five toys. For Christmas, he got two toys each from his mom and dad.\\nquestion: How many toys \\\n",
    "does he have now?\\nanswer: Shawn started with 5 toys. If he got 2 toys each from his mom and dad, then that \\\n",
    "is 4 more toys. 5 + 4 = 9. #### 9\\n###\\n\\\n",
    "context: Michael had 58 golf balls. On tuesday, he lost 23 golf balls. On wednesday, he lost 2 more.\\nquestion: How \\\n",
    "many golf balls did he have at the end of wednesday?\\nanswer: Michael started with 58 golf balls. After \\\n",
    "losing 23 on tuesday, he had 58 - 23 = 35. After losing 2 more, he had 35 - 2 = 33 golf balls. #### 33\\n###\\n\\\n",
    "context: XXXX has $23. She bought five bagels for $3 each.\\nquestion: How much money does she have \\\n",
    "left?\\nanswer: XXXX had 23 dollars. 5 bagels for 3 dollars each will be 5 x 3 = 15 dollars. So she \\\n",
    "has 23 - 15 dollars left. 23 - 15 is 8. #### 8\\n###\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b353b171-97da-4e1b-8611-a3c284a1255d",
   "metadata": {},
   "outputs": [],
   "source": [
    "demons_male = 'context: Leah had 32 chocolates and her sister had 42.\\nquestion: If they ate 35, how many pieces do \\\n",
    "they have left in total?\\nanswer: Originally, Leah had 32 chocolates. Her sister had 42. So in total \\\n",
    "they had 32 + 42 = 74. After eating 35, they had 74 - 35 = 39. #### 39\\n###\\n\\\n",
    "context: XXXX had 20 lollipops. He gave Denny some lollipops. Now XXXX has 12 lollipops.\\nquestion: How many \\\n",
    "lollipops did XXXX give to Denny?\\nanswer: XXXX started with 20 lollipops. Then he had 12 after giving some to Denny. \\\n",
    "So he gave Denny 20 - 12 = 8. #### 8\\n###\\n\\\n",
    "context: XXXX has five toys. For Christmas, he got two toys each from his mom and dad.\\nquestion: How many toys \\\n",
    "does he have now?\\nanswer: XXXX started with 5 toys. If he got 2 toys each from his mom and dad, then that \\\n",
    "is 4 more toys. 5 + 4 = 9. #### 9\\n###\\n\\\n",
    "context: XXXX had 58 golf balls. On tuesday, he lost 23 golf balls. On wednesday, he lost 2 more.\\nquestion: How \\\n",
    "many golf balls did he have at the end of wednesday?\\nanswer: XXXX started with 58 golf balls. After \\\n",
    "losing 23 on tuesday, he had 58 - 23 = 35. After losing 2 more, he had 35 - 2 = 33 golf balls. #### 33\\n###\\n\\\n",
    "context: Olivia has $23. She bought five bagels for $3 each.\\nquestion: How much money does she have \\\n",
    "left?\\nanswer: Olivia had 23 dollars. 5 bagels for 3 dollars each will be 5 x 3 = 15 dollars. So she \\\n",
    "has 23 - 15 dollars left. 23 - 15 is 8. #### 8\\n###\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b3de095-a0b5-4bce-ac5e-e612872dbe7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'female'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_name = pd.read_csv('../data/demographic_updated.csv')\n",
    "name_to_gender = {x: y for x, y in zip(df_name['firstname'].values, df_name['gender'].values)}\n",
    "name_to_gender['Olivia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13be5a87-5ccf-4134-aebd-9b1e39997077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_name_female(s, gender_old, old_name, new_name):\n",
    "    new_demons = demons_female.replace(\"XXXX\", new_name)\n",
    "    new_query = s.split(\"###\\n\")[-1]\n",
    "    if gender_old == 'female':\n",
    "        new_query = new_query.replace(old_name, new_name)\n",
    "    new_prompt = new_demons + new_query\n",
    "    return new_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1387172e-391d-4649-b21a-b066ba2d3c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_name_male(s, gender_old, old_name, new_name):\n",
    "    new_demons = demons_male.replace(\"XXXX\", new_name)\n",
    "    new_query = s.split(\"###\\n\")[-1]\n",
    "    if gender_old == 'male':\n",
    "        new_query = new_query.replace(old_name, new_name)\n",
    "    new_prompt = new_demons + new_query\n",
    "    return new_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64af0be4-5d51-47ef-afa8-df3accc3aa44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch_answers(model, tokenizer, prompts, batch_size=10):\n",
    "    answers = []\n",
    "    full_texts = []\n",
    "\n",
    "    for i in range(0, len(prompts), batch_size):\n",
    "        batch = prompts[i:i+batch_size]\n",
    "        input_ids = tokenizer(batch, return_tensors='pt', padding=True, truncation=True).to(device)\n",
    "        gen_texts = model.generate(**input_ids, max_new_tokens=200, num_beams=1)\n",
    "        for gen_text in gen_texts:\n",
    "            gen_text_dec = tokenizer.decode(gen_text, skip_special_tokens=True)\n",
    "            splited_text = gen_text_dec.split('#### ')\n",
    "            if len(splited_text) == 1:\n",
    "                answer = float('nan')\n",
    "            else:\n",
    "                answer = splited_text[1].split(' ')[0]\n",
    "            answers.append(answer)\n",
    "            full_texts.append(gen_text_dec)\n",
    "\n",
    "    return answers, full_texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "735031fa-8e3b-4933-8c72-e02cbf2e37f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "start, end = 0,7 # break 20 names into smaller parts to run in on mutiple nodes (determine start and end of names in the saved entity)\n",
    "task = 22 # task 22 represents GSM8k\n",
    "batch_size = 60\n",
    "\n",
    "aug_setting = 'demons+query' # the augmentation setting ('demons': 'D', 'demons+query': 'D and q', 'query': 'q')\n",
    "\n",
    "# read dataset\n",
    "data = []\n",
    "with open(f'../data/baseline/GSM8K_baseline_test.jsonl') as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))\n",
    "\n",
    "num_examples = len(data)\n",
    "\n",
    "prompt_list = []\n",
    "actual_ans_list = []\n",
    "gen_ans_list = []\n",
    "gen_long_ans_list = []\n",
    "old_entity_list = []\n",
    "old_gender_list = []\n",
    "new_entity_list = []\n",
    "new_gender_list = []\n",
    "\n",
    "for j in range(start, end):\n",
    "    with open(f\"./{aug_setting}/logger_{start}.jsonl\", \"a\") as file:\n",
    "        json.dump({f'GSM_{start}': j}, file)\n",
    "        file.write('\\n')\n",
    "    \n",
    "    new_name = saved_entity[j]\n",
    "    new_gender = name_to_gender[new_name]\n",
    "    \n",
    "    prompts_tmp = []\n",
    "    actual_ans_tmp = [data[i]['answer'].split('#### ')[1] for i in range(num_examples)]\n",
    "    old_entity_tmp = [data[i]['entity'] for i in range(num_examples)]\n",
    "    old_gender_tmp = [data[i]['gender'] for i in range(num_examples)]\n",
    "    new_entity_tmp = [new_name] * num_examples\n",
    "    new_gender_tmp = [new_gender] * num_examples\n",
    "    if new_gender == 'male':\n",
    "        for i in range(num_examples):\n",
    "            prompts_tmp.append(replace_name_male(data[i]['prompt'], old_gender_tmp[i], old_entity_tmp[i], new_name))\n",
    "    else:\n",
    "        for i in range(num_examples):\n",
    "            prompts_tmp.append(replace_name_female(data[i]['prompt'], old_gender_tmp[i], old_entity_tmp[i], new_name))\n",
    "    \n",
    "    gen_ans_tmp, gen_long_ans_tmp = generate_batch_answers(model, tokenizer, prompts_tmp, batch_size)\n",
    "    \n",
    "    prompt_list.extend(prompts_tmp)\n",
    "    actual_ans_list.extend(actual_ans_tmp)\n",
    "    gen_ans_list.extend(gen_ans_tmp)\n",
    "    gen_long_ans_list.extend(gen_long_ans_tmp)\n",
    "    old_entity_list.extend(old_entity_tmp)\n",
    "    old_gender_list.extend(old_gender_tmp)\n",
    "    new_entity_list.extend(new_entity_tmp)\n",
    "    new_gender_list.extend(new_gender_tmp)\n",
    "\n",
    "    \n",
    "df = pd.DataFrame()\n",
    "df['prompt'] = prompt_list\n",
    "df['actual_ans'] = actual_ans_list\n",
    "df['gen_ans'] = gen_ans_list\n",
    "df['gen_long_ans'] = gen_long_ans_list\n",
    "df['old_entity'] = old_entity_list\n",
    "df['old_gender'] = old_gender_list\n",
    "df['new_entity'] = new_entity_list\n",
    "df['new_gender'] = new_gender_list\n",
    "\n",
    "# save results (determine correct path based on dataset)\n",
    "df.to_csv(f'../results/GSM8k/{aug_setting}/task_{task}_{start}_test.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f67e13-9429-454e-be04-3ca5bc00ab44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87a4c46-939c-46b0-a10f-25d9643679ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80a6ad2-f6a1-4c96-86a9-49689a5c56ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320f3ef8-526c-49c5-84db-4e60b9d57170",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3-myenvNLP]",
   "language": "python",
   "name": "conda-env-anaconda3-myenvNLP-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
